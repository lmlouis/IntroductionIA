{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2pJafD2pPWQzIKQpG4IGJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmlouis/IntroductionIA/blob/main/knn_Iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objective**\n",
        "\n",
        "Implement KNN from scratch \n",
        "\n",
        "The test problem we will be using in this tutorial is the iris classification.\n",
        "\n",
        "The problem consists of 150 observations of iris flowers from three different species. There are 4 measurements of given flowers: sepal length, sepal width, petal length, and petal width (all in the same unit of centimeters). The predicted attribute is the species, which is either Setosa, Versicolor, or Virginica.\n",
        "\n",
        "It is a standard dataset where the species is known for all instances. As such we can split the data into training and test datasets and use the results to evaluate our algorithm implementation. Good classification accuracy on this problem is above 90% correct (typically 96% or better).\n",
        "\n",
        "Save the file in your current working directory with the file name “iris.data“.\n",
        "\n",
        "This tutorial is broken down into the following steps:\n",
        "\n",
        "Handle Data: Open the dataset from CSV and split it into test/train datasets.\n",
        "\n",
        "Similarity: Calculate the distance between two data instances.\n",
        "\n",
        "Neighbors: Locate k for most similar data instances.\n",
        "\n",
        "Response: Generate a response from a set of data instances.\n",
        "\n",
        "Accuracy: Summarize the accuracy of predictions.\n",
        "\n",
        "Main: Tie it all together.\n",
        "\n",
        "**1. Handle Data**\n",
        "\n",
        "The first thing we need to do is load our data file. \n",
        "```\n",
        "import csv \n",
        "with open('iris.data.txt', 'r') as csvfile :\n",
        "  lines = csv.reader(csvfile)\n",
        "\n",
        "  for row in lines :\n",
        "    print (', '.join(row))\n",
        "\n",
        "```\n",
        "\n",
        "Next we need to split the data into a training dataset \n",
        "```\n",
        "import csv\n",
        "\n",
        "import random\n",
        "\n",
        "def loadDataset(filename, split, trainingSet=[] , testSet=[]):\n",
        "\n",
        "with open(filename, 'r') as csvfile:\n",
        "\n",
        "  lines = csv.reader(csvfile)\n",
        "\n",
        "  dataset = list(lines)\n",
        "\n",
        "  for x in range(len(dataset)-1):\n",
        "\n",
        "    for y in range(4):\n",
        "\n",
        "      dataset[x][y] = float(dataset[x][y])\n",
        "\n",
        "    if random.random() < split:\n",
        "\n",
        "      complete code\n",
        "\n",
        "    else:\n",
        "\n",
        "      complete code\n",
        "\n",
        "We can test this function out with our iris dataset, as follows:\n",
        "\n",
        "trainingSet=[]\n",
        "\n",
        "testSet=[]\n",
        "\n",
        "loadDataset('iris.data', 0.66, trainingSet, testSet)\n",
        "\n",
        "print ('Train: ' + repr(len(trainingSet)))\n",
        "\n",
        "print ('Test: ' + repr(len(testSet)) )\n",
        "```\n",
        "**2. Similarity**\n",
        "\n",
        "To make predictions we need to calculate the similarity between any two given data instances. This is needed so that we can locate the k most similar data instances in the training dataset for a given member of the test dataset and in turn, make a prediction.\n",
        "\n",
        "Given that all four flower measurements are numeric and have the same units, we can directly use the Euclidean distance measure. \n",
        "\n",
        "Additionally, we want to control which fields to include in the distance calculation. Specifically, we only want to include the first 4 attributes. One approach is to limit the Euclidean distance to a fixed length, ignoring the final dimension.\n",
        "\n",
        "Putting all of this together, you have to define the Euclidean distance\n",
        "```\n",
        "import math\n",
        "\n",
        "def euclideanDistance(instance1, instance2, length):\n",
        "\n",
        "      Complete the function\n",
        "```\n",
        "Note here that \n",
        "\n",
        "The number of elements in the instance1 equals the number of elements in the instance2 \n",
        "\n",
        "The length refers to the number of elements in the instance1 \n",
        "\n",
        "We can test this function with some sample data, as follows:\n",
        "```\n",
        "data1 = [2, 2, 2, 'a']\n",
        "\n",
        "data2 = [4, 4, 4, 'b']\n",
        "\n",
        "distance = euclideanDistance(data1, data2, 3)\n",
        "\n",
        "print 'Distance: ' + repr(distance)\n",
        "```\n",
        "**3. Neighbors**\n",
        "\n",
        "Now that we have a similarity measure, we can use it to collect the k most similar instances for a given unseen instance.\n",
        "\n",
        "This is a straightforward process of calculating the distance for all instances and selecting a subset with the smallest distance values.\n",
        "\n",
        "Below is the getNeighbors function that returns k most similar neighbors from the training set for a given test instance (using the already defined euclideanDistance function)\n",
        "```\n",
        "import operator\n",
        "\n",
        "def getNeighbors(trainingSet, testInstance, k):\n",
        "\n",
        "distances = []\n",
        "\n",
        "length = len(testInstance)-1\n",
        "\n",
        "for x in range(len(trainingSet)):\n",
        "\n",
        "dist = euclideanDistance(testInstance, trainingSet[x], length)\n",
        "\n",
        "distances.append((trainingSet[x], dist))\n",
        "\n",
        "distances.sort(key=operator.itemgetter(1))\n",
        "\n",
        "neighbors = []\n",
        "\n",
        "for x in range(k):\n",
        "\n",
        "neighbors.append(distances[x][0])\n",
        "\n",
        "return neighbors\n",
        "\n",
        "We can test out this function as follows:\n",
        "\n",
        "trainSet = [[2, 2, 2, 'a'], [4, 4, 4, 'b']]\n",
        "\n",
        "testInstance = [5, 5, 5]\n",
        "\n",
        "k = 1\n",
        "\n",
        "neighbors = getNeighbors(trainSet, testInstance, 1)\n",
        "\n",
        "print(neighbors)\n",
        "```\n",
        "\n",
        "**4. Response**\n",
        "\n",
        "Once we have located the most similar neighbors for a test instance, the next task is to devise a predicted response based on those neighbors.\n",
        "\n",
        "We can do this by allowing each neighbor to vote for their class attribute, and taking the majority vote as the prediction.\n",
        "\n",
        "Below is a function for getting the majority voted response from a number of neighbors. It assumes the class is the last attribute for each neighbor.\n",
        "```\n",
        "import operator\n",
        "\n",
        "def getResponse(neighbors):\n",
        "\n",
        "classVotes = {}\n",
        "\n",
        "for x in range(len(neighbors)):\n",
        "\n",
        "response = neighbors[x][ ? ] #complete with appropriate number\n",
        "\n",
        "if response in classVotes:\n",
        "\n",
        "Complete the if clause\n",
        "\n",
        "sortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse=True)\n",
        "\n",
        "return sortedVotes[0][0]\n",
        "\n",
        "We can test out this function with some test neighbors, as follows:\n",
        "\n",
        "neighbors = [[1,1,1,'a'], [2,2,2,'a'], [3,3,3,'b']]\n",
        "\n",
        "response = getResponse(neighbors)\n",
        "\n",
        "print(response)\n",
        "```\n",
        "This approach returns one response in the case of a draw, but you could handle such cases in a specific way, such as returning no response or selecting an unbiased random response.\n",
        "\n",
        "**5. Accuracy**\n",
        "\n",
        "We have all of the pieces of the KNN algorithm in place. An important remaining concern is how to evaluate the accuracy of predictions.\n",
        "\n",
        "An easy way to evaluate the accuracy of the model is to calculate a ratio of the total correct predictions out of all predictions made, called classification accuracy.\n",
        "\n",
        "Below is the getAccuracy function that sums the total correct predictions and returns the accuracy as a percentage of correct classifications.\n",
        "```\n",
        "def getAccuracy(testSet, predictions):\n",
        "\n",
        "Complete the function\n",
        "\n",
        "return (correct/float(len(testSet))) * 100.0\n",
        "\n",
        "We can test this function with a test dataset and predictions, as follows:\n",
        "\n",
        "testSet = [[1,1,1,'a'], [2,2,2,'a'], [3,3,3,'b']]\n",
        "\n",
        "predictions = ['a', 'a', 'a']\n",
        "\n",
        "accuracy = getAccuracy(testSet, predictions)\n",
        "\n",
        "print(accuracy)\n",
        "```\n",
        "**6. Main**\n",
        "\n",
        "We now have all the elements of the algorithm and  you can put them all in one main function\n",
        "\n",
        "**7. Another distance metric**\n",
        "\n",
        "In this part, you are asked to define another distance metric in addition to the Euclidean distance."
      ],
      "metadata": {
        "id": "zKzXz_lPBIBw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "MZc5m9cRBES1",
        "outputId": "57a7d97d-b5e5-4d14-ab54-d68c3b86d011"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a1ff0c4c-72b1-47e3-acb7-b713b62d378d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a1ff0c4c-72b1-47e3-acb7-b713b62d378d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving iris.data.txt to iris.data.txt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'iris.data.txt': b'5.1,3.5,1.4,0.2,Iris-setosa\\r\\n4.9,3.0,1.4,0.2,Iris-setosa\\r\\n4.7,3.2,1.3,0.2,Iris-setosa\\r\\n4.6,3.1,1.5,0.2,Iris-setosa\\r\\n5.0,3.6,1.4,0.2,Iris-setosa\\r\\n5.4,3.9,1.7,0.4,Iris-setosa\\r\\n4.6,3.4,1.4,0.3,Iris-setosa\\r\\n5.0,3.4,1.5,0.2,Iris-setosa\\r\\n4.4,2.9,1.4,0.2,Iris-setosa\\r\\n4.9,3.1,1.5,0.1,Iris-setosa\\r\\n5.4,3.7,1.5,0.2,Iris-setosa\\r\\n4.8,3.4,1.6,0.2,Iris-setosa\\r\\n4.8,3.0,1.4,0.1,Iris-setosa\\r\\n4.3,3.0,1.1,0.1,Iris-setosa\\r\\n5.8,4.0,1.2,0.2,Iris-setosa\\r\\n5.7,4.4,1.5,0.4,Iris-setosa\\r\\n5.4,3.9,1.3,0.4,Iris-setosa\\r\\n5.1,3.5,1.4,0.3,Iris-setosa\\r\\n5.7,3.8,1.7,0.3,Iris-setosa\\r\\n5.1,3.8,1.5,0.3,Iris-setosa\\r\\n5.4,3.4,1.7,0.2,Iris-setosa\\r\\n5.1,3.7,1.5,0.4,Iris-setosa\\r\\n4.6,3.6,1.0,0.2,Iris-setosa\\r\\n5.1,3.3,1.7,0.5,Iris-setosa\\r\\n4.8,3.4,1.9,0.2,Iris-setosa\\r\\n5.0,3.0,1.6,0.2,Iris-setosa\\r\\n5.0,3.4,1.6,0.4,Iris-setosa\\r\\n5.2,3.5,1.5,0.2,Iris-setosa\\r\\n5.2,3.4,1.4,0.2,Iris-setosa\\r\\n4.7,3.2,1.6,0.2,Iris-setosa\\r\\n4.8,3.1,1.6,0.2,Iris-setosa\\r\\n5.4,3.4,1.5,0.4,Iris-setosa\\r\\n5.2,4.1,1.5,0.1,Iris-setosa\\r\\n5.5,4.2,1.4,0.2,Iris-setosa\\r\\n4.9,3.1,1.5,0.1,Iris-setosa\\r\\n5.0,3.2,1.2,0.2,Iris-setosa\\r\\n5.5,3.5,1.3,0.2,Iris-setosa\\r\\n4.9,3.1,1.5,0.1,Iris-setosa\\r\\n4.4,3.0,1.3,0.2,Iris-setosa\\r\\n5.1,3.4,1.5,0.2,Iris-setosa\\r\\n5.0,3.5,1.3,0.3,Iris-setosa\\r\\n4.5,2.3,1.3,0.3,Iris-setosa\\r\\n4.4,3.2,1.3,0.2,Iris-setosa\\r\\n5.0,3.5,1.6,0.6,Iris-setosa\\r\\n5.1,3.8,1.9,0.4,Iris-setosa\\r\\n4.8,3.0,1.4,0.3,Iris-setosa\\r\\n5.1,3.8,1.6,0.2,Iris-setosa\\r\\n4.6,3.2,1.4,0.2,Iris-setosa\\r\\n5.3,3.7,1.5,0.2,Iris-setosa\\r\\n5.0,3.3,1.4,0.2,Iris-setosa\\r\\n7.0,3.2,4.7,1.4,Iris-versicolor\\r\\n6.4,3.2,4.5,1.5,Iris-versicolor\\r\\n6.9,3.1,4.9,1.5,Iris-versicolor\\r\\n5.5,2.3,4.0,1.3,Iris-versicolor\\r\\n6.5,2.8,4.6,1.5,Iris-versicolor\\r\\n5.7,2.8,4.5,1.3,Iris-versicolor\\r\\n6.3,3.3,4.7,1.6,Iris-versicolor\\r\\n4.9,2.4,3.3,1.0,Iris-versicolor\\r\\n6.6,2.9,4.6,1.3,Iris-versicolor\\r\\n5.2,2.7,3.9,1.4,Iris-versicolor\\r\\n5.0,2.0,3.5,1.0,Iris-versicolor\\r\\n5.9,3.0,4.2,1.5,Iris-versicolor\\r\\n6.0,2.2,4.0,1.0,Iris-versicolor\\r\\n6.1,2.9,4.7,1.4,Iris-versicolor\\r\\n5.6,2.9,3.6,1.3,Iris-versicolor\\r\\n6.7,3.1,4.4,1.4,Iris-versicolor\\r\\n5.6,3.0,4.5,1.5,Iris-versicolor\\r\\n5.8,2.7,4.1,1.0,Iris-versicolor\\r\\n6.2,2.2,4.5,1.5,Iris-versicolor\\r\\n5.6,2.5,3.9,1.1,Iris-versicolor\\r\\n5.9,3.2,4.8,1.8,Iris-versicolor\\r\\n6.1,2.8,4.0,1.3,Iris-versicolor\\r\\n6.3,2.5,4.9,1.5,Iris-versicolor\\r\\n6.1,2.8,4.7,1.2,Iris-versicolor\\r\\n6.4,2.9,4.3,1.3,Iris-versicolor\\r\\n6.6,3.0,4.4,1.4,Iris-versicolor\\r\\n6.8,2.8,4.8,1.4,Iris-versicolor\\r\\n6.7,3.0,5.0,1.7,Iris-versicolor\\r\\n6.0,2.9,4.5,1.5,Iris-versicolor\\r\\n5.7,2.6,3.5,1.0,Iris-versicolor\\r\\n5.5,2.4,3.8,1.1,Iris-versicolor\\r\\n5.5,2.4,3.7,1.0,Iris-versicolor\\r\\n5.8,2.7,3.9,1.2,Iris-versicolor\\r\\n6.0,2.7,5.1,1.6,Iris-versicolor\\r\\n5.4,3.0,4.5,1.5,Iris-versicolor\\r\\n6.0,3.4,4.5,1.6,Iris-versicolor\\r\\n6.7,3.1,4.7,1.5,Iris-versicolor\\r\\n6.3,2.3,4.4,1.3,Iris-versicolor\\r\\n5.6,3.0,4.1,1.3,Iris-versicolor\\r\\n5.5,2.5,4.0,1.3,Iris-versicolor\\r\\n5.5,2.6,4.4,1.2,Iris-versicolor\\r\\n6.1,3.0,4.6,1.4,Iris-versicolor\\r\\n5.8,2.6,4.0,1.2,Iris-versicolor\\r\\n5.0,2.3,3.3,1.0,Iris-versicolor\\r\\n5.6,2.7,4.2,1.3,Iris-versicolor\\r\\n5.7,3.0,4.2,1.2,Iris-versicolor\\r\\n5.7,2.9,4.2,1.3,Iris-versicolor\\r\\n6.2,2.9,4.3,1.3,Iris-versicolor\\r\\n5.1,2.5,3.0,1.1,Iris-versicolor\\r\\n5.7,2.8,4.1,1.3,Iris-versicolor\\r\\n6.3,3.3,6.0,2.5,Iris-virginica\\r\\n5.8,2.7,5.1,1.9,Iris-virginica\\r\\n7.1,3.0,5.9,2.1,Iris-virginica\\r\\n6.3,2.9,5.6,1.8,Iris-virginica\\r\\n6.5,3.0,5.8,2.2,Iris-virginica\\r\\n7.6,3.0,6.6,2.1,Iris-virginica\\r\\n4.9,2.5,4.5,1.7,Iris-virginica\\r\\n7.3,2.9,6.3,1.8,Iris-virginica\\r\\n6.7,2.5,5.8,1.8,Iris-virginica\\r\\n7.2,3.6,6.1,2.5,Iris-virginica\\r\\n6.5,3.2,5.1,2.0,Iris-virginica\\r\\n6.4,2.7,5.3,1.9,Iris-virginica\\r\\n6.8,3.0,5.5,2.1,Iris-virginica\\r\\n5.7,2.5,5.0,2.0,Iris-virginica\\r\\n5.8,2.8,5.1,2.4,Iris-virginica\\r\\n6.4,3.2,5.3,2.3,Iris-virginica\\r\\n6.5,3.0,5.5,1.8,Iris-virginica\\r\\n7.7,3.8,6.7,2.2,Iris-virginica\\r\\n7.7,2.6,6.9,2.3,Iris-virginica\\r\\n6.0,2.2,5.0,1.5,Iris-virginica\\r\\n6.9,3.2,5.7,2.3,Iris-virginica\\r\\n5.6,2.8,4.9,2.0,Iris-virginica\\r\\n7.7,2.8,6.7,2.0,Iris-virginica\\r\\n6.3,2.7,4.9,1.8,Iris-virginica\\r\\n6.7,3.3,5.7,2.1,Iris-virginica\\r\\n7.2,3.2,6.0,1.8,Iris-virginica\\r\\n6.2,2.8,4.8,1.8,Iris-virginica\\r\\n6.1,3.0,4.9,1.8,Iris-virginica\\r\\n6.4,2.8,5.6,2.1,Iris-virginica\\r\\n7.2,3.0,5.8,1.6,Iris-virginica\\r\\n7.4,2.8,6.1,1.9,Iris-virginica\\r\\n7.9,3.8,6.4,2.0,Iris-virginica\\r\\n6.4,2.8,5.6,2.2,Iris-virginica\\r\\n6.3,2.8,5.1,1.5,Iris-virginica\\r\\n6.1,2.6,5.6,1.4,Iris-virginica\\r\\n7.7,3.0,6.1,2.3,Iris-virginica\\r\\n6.3,3.4,5.6,2.4,Iris-virginica\\r\\n6.4,3.1,5.5,1.8,Iris-virginica\\r\\n6.0,3.0,4.8,1.8,Iris-virginica\\r\\n6.9,3.1,5.4,2.1,Iris-virginica\\r\\n6.7,3.1,5.6,2.4,Iris-virginica\\r\\n6.9,3.1,5.1,2.3,Iris-virginica\\r\\n5.8,2.7,5.1,1.9,Iris-virginica\\r\\n6.8,3.2,5.9,2.3,Iris-virginica\\r\\n6.7,3.3,5.7,2.5,Iris-virginica\\r\\n6.7,3.0,5.2,2.3,Iris-virginica\\r\\n6.3,2.5,5.0,1.9,Iris-virginica\\r\\n6.5,3.0,5.2,2.0,Iris-virginica\\r\\n6.2,3.4,5.4,2.3,Iris-virginica\\r\\n5.9,3.0,5.1,1.8,Iris-virginica\\r\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.view('/content/iris.data.txt') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "KtjlXkApCpFr",
        "outputId": "0c85fbef-3277-4a28-d3aa-47538577d690"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "      ((filepath) => {{\n",
              "        if (!google.colab.kernel.accessAllowed) {{\n",
              "          return;\n",
              "        }}\n",
              "        google.colab.files.view(filepath);\n",
              "      }})(\"/content/iris.data.txt\")"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Handle Data\n",
        "\n",
        "The first thing we need to do is load our data file.\n",
        "```\n",
        "import csv\n",
        "\n",
        "with open('iris.data.txt', 'r') as csvfile:\n",
        "\n",
        "lines = csv.reader(csvfile)\n",
        "\n",
        "for row in lines :\n",
        "\n",
        "print (', '.join(row))\n",
        "```\n",
        "Next we need to split the data into a training dataset\n",
        "```\n",
        "import csv\n",
        "\n",
        "import random\n",
        "\n",
        "def loadDataset(filename, split, trainingSet=[] , testSet=[]):\n",
        "\n",
        "with open(filename, 'r') as csvfile:\n",
        "\n",
        "lines = csv.reader(csvfile)\n",
        "\n",
        "dataset = list(lines)\n",
        "\n",
        "for x in range(len(dataset)-1):\n",
        "\n",
        "for y in range(4):\n",
        "\n",
        "  dataset[x][y] = float(dataset[x][y])\n",
        "\n",
        "if random.random() < split:\n",
        "\n",
        "  complete code\n",
        "\n",
        "else:\n",
        "\n",
        "  complete code\n",
        "We can test this function out with our iris dataset, as follows:\n",
        "\n",
        "trainingSet=[]\n",
        "\n",
        "testSet=[]\n",
        "\n",
        "loadDataset('iris.data', 0.66, trainingSet, testSet)\n",
        "\n",
        "print ('Train: ' + repr(len(trainingSet)))\n",
        "\n",
        "print ('Test: ' + repr(len(testSet)) )\n",
        "```"
      ],
      "metadata": {
        "id": "MdjJVJ7eDKBd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Charger notre fichier de données "
      ],
      "metadata": {
        "id": "jZQrnKliHJgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv \n",
        "with open('iris.data.txt', 'r') as csvfile :\n",
        "  lines = csv.reader(csvfile)\n",
        "\n",
        "  for row in lines :\n",
        "    print (', '.join(row))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGLcwdarDJf3",
        "outputId": "aacb53c3-44f1-4c12-f55d-f326a4406169"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.1, 3.5, 1.4, 0.2, Iris-setosa\n",
            "4.9, 3.0, 1.4, 0.2, Iris-setosa\n",
            "4.7, 3.2, 1.3, 0.2, Iris-setosa\n",
            "4.6, 3.1, 1.5, 0.2, Iris-setosa\n",
            "5.0, 3.6, 1.4, 0.2, Iris-setosa\n",
            "5.4, 3.9, 1.7, 0.4, Iris-setosa\n",
            "4.6, 3.4, 1.4, 0.3, Iris-setosa\n",
            "5.0, 3.4, 1.5, 0.2, Iris-setosa\n",
            "4.4, 2.9, 1.4, 0.2, Iris-setosa\n",
            "4.9, 3.1, 1.5, 0.1, Iris-setosa\n",
            "5.4, 3.7, 1.5, 0.2, Iris-setosa\n",
            "4.8, 3.4, 1.6, 0.2, Iris-setosa\n",
            "4.8, 3.0, 1.4, 0.1, Iris-setosa\n",
            "4.3, 3.0, 1.1, 0.1, Iris-setosa\n",
            "5.8, 4.0, 1.2, 0.2, Iris-setosa\n",
            "5.7, 4.4, 1.5, 0.4, Iris-setosa\n",
            "5.4, 3.9, 1.3, 0.4, Iris-setosa\n",
            "5.1, 3.5, 1.4, 0.3, Iris-setosa\n",
            "5.7, 3.8, 1.7, 0.3, Iris-setosa\n",
            "5.1, 3.8, 1.5, 0.3, Iris-setosa\n",
            "5.4, 3.4, 1.7, 0.2, Iris-setosa\n",
            "5.1, 3.7, 1.5, 0.4, Iris-setosa\n",
            "4.6, 3.6, 1.0, 0.2, Iris-setosa\n",
            "5.1, 3.3, 1.7, 0.5, Iris-setosa\n",
            "4.8, 3.4, 1.9, 0.2, Iris-setosa\n",
            "5.0, 3.0, 1.6, 0.2, Iris-setosa\n",
            "5.0, 3.4, 1.6, 0.4, Iris-setosa\n",
            "5.2, 3.5, 1.5, 0.2, Iris-setosa\n",
            "5.2, 3.4, 1.4, 0.2, Iris-setosa\n",
            "4.7, 3.2, 1.6, 0.2, Iris-setosa\n",
            "4.8, 3.1, 1.6, 0.2, Iris-setosa\n",
            "5.4, 3.4, 1.5, 0.4, Iris-setosa\n",
            "5.2, 4.1, 1.5, 0.1, Iris-setosa\n",
            "5.5, 4.2, 1.4, 0.2, Iris-setosa\n",
            "4.9, 3.1, 1.5, 0.1, Iris-setosa\n",
            "5.0, 3.2, 1.2, 0.2, Iris-setosa\n",
            "5.5, 3.5, 1.3, 0.2, Iris-setosa\n",
            "4.9, 3.1, 1.5, 0.1, Iris-setosa\n",
            "4.4, 3.0, 1.3, 0.2, Iris-setosa\n",
            "5.1, 3.4, 1.5, 0.2, Iris-setosa\n",
            "5.0, 3.5, 1.3, 0.3, Iris-setosa\n",
            "4.5, 2.3, 1.3, 0.3, Iris-setosa\n",
            "4.4, 3.2, 1.3, 0.2, Iris-setosa\n",
            "5.0, 3.5, 1.6, 0.6, Iris-setosa\n",
            "5.1, 3.8, 1.9, 0.4, Iris-setosa\n",
            "4.8, 3.0, 1.4, 0.3, Iris-setosa\n",
            "5.1, 3.8, 1.6, 0.2, Iris-setosa\n",
            "4.6, 3.2, 1.4, 0.2, Iris-setosa\n",
            "5.3, 3.7, 1.5, 0.2, Iris-setosa\n",
            "5.0, 3.3, 1.4, 0.2, Iris-setosa\n",
            "7.0, 3.2, 4.7, 1.4, Iris-versicolor\n",
            "6.4, 3.2, 4.5, 1.5, Iris-versicolor\n",
            "6.9, 3.1, 4.9, 1.5, Iris-versicolor\n",
            "5.5, 2.3, 4.0, 1.3, Iris-versicolor\n",
            "6.5, 2.8, 4.6, 1.5, Iris-versicolor\n",
            "5.7, 2.8, 4.5, 1.3, Iris-versicolor\n",
            "6.3, 3.3, 4.7, 1.6, Iris-versicolor\n",
            "4.9, 2.4, 3.3, 1.0, Iris-versicolor\n",
            "6.6, 2.9, 4.6, 1.3, Iris-versicolor\n",
            "5.2, 2.7, 3.9, 1.4, Iris-versicolor\n",
            "5.0, 2.0, 3.5, 1.0, Iris-versicolor\n",
            "5.9, 3.0, 4.2, 1.5, Iris-versicolor\n",
            "6.0, 2.2, 4.0, 1.0, Iris-versicolor\n",
            "6.1, 2.9, 4.7, 1.4, Iris-versicolor\n",
            "5.6, 2.9, 3.6, 1.3, Iris-versicolor\n",
            "6.7, 3.1, 4.4, 1.4, Iris-versicolor\n",
            "5.6, 3.0, 4.5, 1.5, Iris-versicolor\n",
            "5.8, 2.7, 4.1, 1.0, Iris-versicolor\n",
            "6.2, 2.2, 4.5, 1.5, Iris-versicolor\n",
            "5.6, 2.5, 3.9, 1.1, Iris-versicolor\n",
            "5.9, 3.2, 4.8, 1.8, Iris-versicolor\n",
            "6.1, 2.8, 4.0, 1.3, Iris-versicolor\n",
            "6.3, 2.5, 4.9, 1.5, Iris-versicolor\n",
            "6.1, 2.8, 4.7, 1.2, Iris-versicolor\n",
            "6.4, 2.9, 4.3, 1.3, Iris-versicolor\n",
            "6.6, 3.0, 4.4, 1.4, Iris-versicolor\n",
            "6.8, 2.8, 4.8, 1.4, Iris-versicolor\n",
            "6.7, 3.0, 5.0, 1.7, Iris-versicolor\n",
            "6.0, 2.9, 4.5, 1.5, Iris-versicolor\n",
            "5.7, 2.6, 3.5, 1.0, Iris-versicolor\n",
            "5.5, 2.4, 3.8, 1.1, Iris-versicolor\n",
            "5.5, 2.4, 3.7, 1.0, Iris-versicolor\n",
            "5.8, 2.7, 3.9, 1.2, Iris-versicolor\n",
            "6.0, 2.7, 5.1, 1.6, Iris-versicolor\n",
            "5.4, 3.0, 4.5, 1.5, Iris-versicolor\n",
            "6.0, 3.4, 4.5, 1.6, Iris-versicolor\n",
            "6.7, 3.1, 4.7, 1.5, Iris-versicolor\n",
            "6.3, 2.3, 4.4, 1.3, Iris-versicolor\n",
            "5.6, 3.0, 4.1, 1.3, Iris-versicolor\n",
            "5.5, 2.5, 4.0, 1.3, Iris-versicolor\n",
            "5.5, 2.6, 4.4, 1.2, Iris-versicolor\n",
            "6.1, 3.0, 4.6, 1.4, Iris-versicolor\n",
            "5.8, 2.6, 4.0, 1.2, Iris-versicolor\n",
            "5.0, 2.3, 3.3, 1.0, Iris-versicolor\n",
            "5.6, 2.7, 4.2, 1.3, Iris-versicolor\n",
            "5.7, 3.0, 4.2, 1.2, Iris-versicolor\n",
            "5.7, 2.9, 4.2, 1.3, Iris-versicolor\n",
            "6.2, 2.9, 4.3, 1.3, Iris-versicolor\n",
            "5.1, 2.5, 3.0, 1.1, Iris-versicolor\n",
            "5.7, 2.8, 4.1, 1.3, Iris-versicolor\n",
            "6.3, 3.3, 6.0, 2.5, Iris-virginica\n",
            "5.8, 2.7, 5.1, 1.9, Iris-virginica\n",
            "7.1, 3.0, 5.9, 2.1, Iris-virginica\n",
            "6.3, 2.9, 5.6, 1.8, Iris-virginica\n",
            "6.5, 3.0, 5.8, 2.2, Iris-virginica\n",
            "7.6, 3.0, 6.6, 2.1, Iris-virginica\n",
            "4.9, 2.5, 4.5, 1.7, Iris-virginica\n",
            "7.3, 2.9, 6.3, 1.8, Iris-virginica\n",
            "6.7, 2.5, 5.8, 1.8, Iris-virginica\n",
            "7.2, 3.6, 6.1, 2.5, Iris-virginica\n",
            "6.5, 3.2, 5.1, 2.0, Iris-virginica\n",
            "6.4, 2.7, 5.3, 1.9, Iris-virginica\n",
            "6.8, 3.0, 5.5, 2.1, Iris-virginica\n",
            "5.7, 2.5, 5.0, 2.0, Iris-virginica\n",
            "5.8, 2.8, 5.1, 2.4, Iris-virginica\n",
            "6.4, 3.2, 5.3, 2.3, Iris-virginica\n",
            "6.5, 3.0, 5.5, 1.8, Iris-virginica\n",
            "7.7, 3.8, 6.7, 2.2, Iris-virginica\n",
            "7.7, 2.6, 6.9, 2.3, Iris-virginica\n",
            "6.0, 2.2, 5.0, 1.5, Iris-virginica\n",
            "6.9, 3.2, 5.7, 2.3, Iris-virginica\n",
            "5.6, 2.8, 4.9, 2.0, Iris-virginica\n",
            "7.7, 2.8, 6.7, 2.0, Iris-virginica\n",
            "6.3, 2.7, 4.9, 1.8, Iris-virginica\n",
            "6.7, 3.3, 5.7, 2.1, Iris-virginica\n",
            "7.2, 3.2, 6.0, 1.8, Iris-virginica\n",
            "6.2, 2.8, 4.8, 1.8, Iris-virginica\n",
            "6.1, 3.0, 4.9, 1.8, Iris-virginica\n",
            "6.4, 2.8, 5.6, 2.1, Iris-virginica\n",
            "7.2, 3.0, 5.8, 1.6, Iris-virginica\n",
            "7.4, 2.8, 6.1, 1.9, Iris-virginica\n",
            "7.9, 3.8, 6.4, 2.0, Iris-virginica\n",
            "6.4, 2.8, 5.6, 2.2, Iris-virginica\n",
            "6.3, 2.8, 5.1, 1.5, Iris-virginica\n",
            "6.1, 2.6, 5.6, 1.4, Iris-virginica\n",
            "7.7, 3.0, 6.1, 2.3, Iris-virginica\n",
            "6.3, 3.4, 5.6, 2.4, Iris-virginica\n",
            "6.4, 3.1, 5.5, 1.8, Iris-virginica\n",
            "6.0, 3.0, 4.8, 1.8, Iris-virginica\n",
            "6.9, 3.1, 5.4, 2.1, Iris-virginica\n",
            "6.7, 3.1, 5.6, 2.4, Iris-virginica\n",
            "6.9, 3.1, 5.1, 2.3, Iris-virginica\n",
            "5.8, 2.7, 5.1, 1.9, Iris-virginica\n",
            "6.8, 3.2, 5.9, 2.3, Iris-virginica\n",
            "6.7, 3.3, 5.7, 2.5, Iris-virginica\n",
            "6.7, 3.0, 5.2, 2.3, Iris-virginica\n",
            "6.3, 2.5, 5.0, 1.9, Iris-virginica\n",
            "6.5, 3.0, 5.2, 2.0, Iris-virginica\n",
            "6.2, 3.4, 5.4, 2.3, Iris-virginica\n",
            "5.9, 3.0, 5.1, 1.8, Iris-virginica\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## split the data into a training dataset"
      ],
      "metadata": {
        "id": "ISkg44AsHaf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "import random\n",
        "\n",
        "def loadDataset(filename, split, trainingSet=[] , testSet=[]):\n",
        "    ''' Fait le split de données de training d'un fichier csv '''\n",
        "    with open(filename, 'r') as csvfile:\n",
        "\n",
        "      lines = csv.reader(csvfile)\n",
        "\n",
        "      dataset = list(lines)\n",
        "\n",
        "      for x in range(len(dataset)-1):\n",
        "\n",
        "        for y in range(4):\n",
        "\n",
        "          dataset[x][y] = float(dataset[x][y])\n",
        "\n",
        "        if random.random() < split:\n",
        "\n",
        "          #complete code\n",
        "          trainingSet.append(dataset[x])\n",
        "\n",
        "        else:\n",
        "\n",
        "          #   complete code\n",
        "          testSet.append(dataset[x])\n",
        "\n",
        "# We can test this function out with our iris dataset, as follows:\n",
        "        \n",
        "\n",
        "trainingSet=[]\n",
        "\n",
        "testSet=[]\n",
        "\n",
        "loadDataset('iris.data.txt', 0.66, trainingSet, testSet)\n",
        "\n",
        "print ('Train: ' + repr(len(trainingSet)))\n",
        "\n",
        "print ('Test: ' + repr(len(testSet)) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnylKja0EqKI",
        "outputId": "dae75f24-9908-4baa-f7ff-96dcdf691e2d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 91\n",
            "Test: 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**2. Similarity**\n",
        "\n",
        "To make predictions we need to calculate the similarity between any two given data instances. This is needed so that we can locate the k most similar data instances in the training dataset for a given member of the test dataset and in turn, make a prediction.\n",
        "\n",
        "Given that all four flower measurements are numeric and have the same units, we can directly use the Euclidean distance measure. \n",
        "\n",
        "Additionally, we want to control which fields to include in the distance calculation. Specifically, we only want to include the first 4 attributes. One approach is to limit the Euclidean distance to a fixed length, ignoring the final dimension.\n",
        "\n",
        "Putting all of this together, you have to define the Euclidean distance\n",
        "```\n",
        "import math\n",
        "\n",
        "def euclideanDistance(instance1, instance2, length):\n",
        "\n",
        "      Complete the function\n",
        "```\n",
        "Note here that \n",
        "\n",
        "The number of elements in the instance1 equals the number of elements in the instance2 \n",
        "\n",
        "The length refers to the number of elements in the instance1 \n",
        "\n",
        "We can test this function with some sample data, as follows:\n",
        "```\n",
        "data1 = [2, 2, 2, 'a']\n",
        "\n",
        "data2 = [4, 4, 4, 'b']\n",
        "\n",
        "distance = euclideanDistance(data1, data2, 3)\n",
        "\n",
        "print 'Distance: ' + repr(distance)\n",
        "```"
      ],
      "metadata": {
        "id": "Z60rlxlrH9fZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distance euclidienne "
      ],
      "metadata": {
        "id": "svEp_f4zK70E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def euclideanDistance(instance1, instance2, length):\n",
        "  ''' Calcul la distance euclidienne entre instance1 et instance2 : \n",
        "   d = √ somme( (instance1(x) − instance2(x) )**2 ) pour chaque x dans length '''\n",
        "  distance = 0\n",
        "  for x in range(length):\n",
        "    distance += pow((instance1[x] - instance2[x]), 2)\n",
        "  return math.sqrt(distance)"
      ],
      "metadata": {
        "id": "daopTDjhIF-g"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test de la fonction"
      ],
      "metadata": {
        "id": "XB_5CBgLLAgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = [2, 2, 2, 'a']\n",
        "\n",
        "data2 = [4, 4, 4, 'b']\n",
        "\n",
        "distance = euclideanDistance(data1, data2, 3)\n",
        "\n",
        "print(f'Distance: {repr(distance)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNCstlFIKU7q",
        "outputId": "2b4fd16d-4562-4e82-a832-5d019287a91d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance: 3.4641016151377544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Neighbors**\n",
        "\n",
        "Now that we have a similarity measure, we can use it to collect the k most similar instances for a given unseen instance.\n",
        "\n",
        "This is a straightforward process of calculating the distance for all instances and selecting a subset with the smallest distance values.\n",
        "\n",
        "Below is the getNeighbors function that returns k most similar neighbors from the training set for a given test instance (using the already defined euclideanDistance function)\n",
        "```\n",
        "import operator\n",
        "\n",
        "def getNeighbors(trainingSet, testInstance, k):\n",
        "\n",
        "distances = []\n",
        "\n",
        "length = len(testInstance)-1\n",
        "\n",
        "for x in range(len(trainingSet)):\n",
        "\n",
        "dist = euclideanDistance(testInstance, trainingSet[x], length)\n",
        "\n",
        "distances.append((trainingSet[x], dist))\n",
        "\n",
        "distances.sort(key=operator.itemgetter(1))\n",
        "\n",
        "neighbors = []\n",
        "\n",
        "for x in range(k):\n",
        "\n",
        "neighbors.append(distances[x][0])\n",
        "\n",
        "return neighbors\n",
        "```\n",
        "We can test out this function as follows:\n",
        "```\n",
        "trainSet = [[2, 2, 2, 'a'], [4, 4, 4, 'b']]\n",
        "\n",
        "testInstance = [5, 5, 5]\n",
        "\n",
        "k = 1\n",
        "\n",
        "neighbors = getNeighbors(trainSet, testInstance, 1)\n",
        "\n",
        "print(neighbors)\n",
        "```"
      ],
      "metadata": {
        "id": "Mk1nviJBLSKC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### obtenir ses proches voisin"
      ],
      "metadata": {
        "id": "7Iob4KBmL2ZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "\n",
        "def getNeighbors(trainingSet, testInstance, k):\n",
        "\n",
        "  distances = []\n",
        "\n",
        "  length = len(testInstance)-1\n",
        "\n",
        "  for x in range(len(trainingSet)):\n",
        "\n",
        "    dist = euclideanDistance(testInstance, trainingSet[x], length)\n",
        "\n",
        "    distances.append((trainingSet[x], dist))\n",
        "\n",
        "    distances.sort(key=operator.itemgetter(1))\n",
        "\n",
        "    neighbors = []\n",
        "\n",
        "  for x in range(k):\n",
        "\n",
        "    neighbors.append(distances[x][0])\n",
        "\n",
        "  return neighbors"
      ],
      "metadata": {
        "id": "WYNJA7kALk-m"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test de la fonction"
      ],
      "metadata": {
        "id": "v2gaT7QyL7Xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainSet = [[2, 2, 2, 'a'], [4, 4, 4, 'b']]\n",
        "\n",
        "testInstance = [5, 5, 5]\n",
        "\n",
        "k = 1\n",
        "\n",
        "neighbors = getNeighbors(trainSet, testInstance, 1)\n",
        "\n",
        "print(\"dans [[2, 2, 2, 'a'], [4, 4, 4, 'b']],\\nPour k = 1 , [5, 5, 5] est voisin à \", neighbors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9XgdQklMBLC",
        "outputId": "c23f2fa7-7f4f-4507-f49f-b52e84b149ac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dans [[2, 2, 2, 'a'], [4, 4, 4, 'b']],\n",
            "Pour k = 1 , [5, 5, 5] est voisin à  [[4, 4, 4, 'b']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Response**\n",
        "\n",
        "Once we have located the most similar neighbors for a test instance, the next task is to devise a predicted response based on those neighbors.\n",
        "\n",
        "We can do this by allowing each neighbor to vote for their class attribute, and taking the majority vote as the prediction.\n",
        "\n",
        "Below is a function for getting the majority voted response from a number of neighbors. It assumes the class is the last attribute for each neighbor.\n",
        "```\n",
        "import operator\n",
        "\n",
        "def getResponse(neighbors):\n",
        "\n",
        "classVotes = {}\n",
        "\n",
        "for x in range(len(neighbors)):\n",
        "\n",
        "response = neighbors[x][ ? ] #complete with appropriate number\n",
        "\n",
        "if response in classVotes:\n",
        "\n",
        "Complete the if clause\n",
        "\n",
        "sortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse=True)\n",
        "\n",
        "return sortedVotes[0][0]\n",
        "```\n",
        "We can test out this function with some test neighbors, as follows:\n",
        "```\n",
        "neighbors = [[1,1,1,'a'], [2,2,2,'a'], [3,3,3,'b']]\n",
        "\n",
        "response = getResponse(neighbors)\n",
        "\n",
        "print(response)\n",
        "```\n",
        "This approach returns one response in the case of a draw, but you could handle such cases in a specific way, such as returning no response or selecting an unbiased random response.\n"
      ],
      "metadata": {
        "id": "UOfTKoo4NPEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "\n",
        "def getResponse(neighbors):\n",
        "  ''' Créer une liste de tous les voisins possibles '''\n",
        "\n",
        "  classVotes = {}\n",
        "\n",
        "  for x in range(len(neighbors)):\n",
        "    # la reponse contient le dernier élément de la liste  soit list[x][-1]\n",
        "    response = neighbors[x][-1] #complete with appropriate number\n",
        "\n",
        "    if response in classVotes:\n",
        "      classVotes[response] += 1\n",
        "    else:\n",
        "      classVotes[response] = 1\n",
        "\n",
        "  sortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse=True)\n",
        "\n",
        "  return sortedVotes[0][0]\n",
        "\n"
      ],
      "metadata": {
        "id": "mIcmEa6bNbLq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neighbors = [[1,1,1,'a'], [2,2,2,'a'], [3,3,3,'b']]\n",
        "\n",
        "response = getResponse(neighbors)\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tL0lh8vdDi2U",
        "outputId": "4a35d708-f332-44ac-f474-2a042d66a795"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**5. Accuracy**\n",
        "\n",
        "We have all of the pieces of the KNN algorithm in place. An important remaining concern is how to evaluate the accuracy of predictions.\n",
        "\n",
        "An easy way to evaluate the accuracy of the model is to calculate a ratio of the total correct predictions out of all predictions made, called classification accuracy.\n",
        "\n",
        "Below is the getAccuracy function that sums the total correct predictions and returns the accuracy as a percentage of correct classifications.\n",
        "```\n",
        "def getAccuracy(testSet, predictions):\n",
        "\n",
        "Complete the function\n",
        "\n",
        "return (correct/float(len(testSet))) * 100.0\n",
        "```\n",
        "We can test this function with a test dataset and predictions, as follows:\n",
        "```\n",
        "testSet = [[1,1,1,'a'], [2,2,2,'a'], [3,3,3,'b']]\n",
        "\n",
        "predictions = ['a', 'a', 'a']\n",
        "\n",
        "accuracy = getAccuracy(testSet, predictions)\n",
        "\n",
        "print(accuracy)\n",
        "```"
      ],
      "metadata": {
        "id": "MdFTmCkFu-u3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Créer la fonction getAccuracy : renvoie le pourcentage de score prédit si les données de test est égal aux données prédictes"
      ],
      "metadata": {
        "id": "EPVSCL78wHqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getAccuracy(testSet, predictions):\n",
        "  '''Calcul la métric du KNN accuracy en %'''\n",
        "  #Complete the function\n",
        "  correct = 0\n",
        "  for x in range(len(testSet)):\n",
        "    if testSet[x][-1] == predictions[x]:\n",
        "      correct += 1\n",
        "\n",
        "  return (correct/float(len(testSet))) * 100.0"
      ],
      "metadata": {
        "id": "UjuP4NNrvHTI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tester la fonction getAccuracy "
      ],
      "metadata": {
        "id": "Or20n2dPwDhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testSet = [[1,1,1,'a'], [2,2,2,'a'], [3,3,3,'b']]\n",
        "\n",
        "predictions = ['a', 'a', 'a']\n",
        "\n",
        "accuracy = getAccuracy(testSet, predictions)\n",
        "\n",
        "print(\"predictions = ['a', 'a', 'a'] parmis les voisins testSet = [[1,1,1,'a'], [2,2,2,'a'], [3,3,3,'b']] est de \", accuracy,\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxwS15wXvt_j",
        "outputId": "662e70bd-3038-4214-faea-3491452176d9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions = ['a', 'a', 'a'] parmis les voisins testSet = [[1,1,1,'a'], [2,2,2,'a'], [3,3,3,'b']] est de  66.66666666666666 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Main\n",
        "\n",
        "We now have all the elements of the algorithm and you can put them all in one main function"
      ],
      "metadata": {
        "id": "au4rv4_IxM8x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Créer une fontion main pour génerer notre modèl de KNN"
      ],
      "metadata": {
        "id": "Kw0ryJhFxWYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # plit data \n",
        "    trainingSet=[]\n",
        "    testSet=[]\n",
        "    split = 0.67\n",
        "    # load dataset\n",
        "    loadDataset('iris.data.txt', split, trainingSet, testSet)\n",
        "    print('Train set: ' + repr(len(trainingSet)) )\n",
        "    print('Test set: ' + repr(len(testSet))  )   \n",
        "    # initialize prediction data and k value\n",
        "    predictions=[]\n",
        "    k = 3\n",
        "    for x in range(len(testSet)):\n",
        "        # search neighbors for k specific value \n",
        "        neighbors = getNeighbors(trainingSet, testSet[x], k)\n",
        "        # get the k nearest neighbors \n",
        "        result = getResponse(neighbors)\n",
        "        # implement prediction data \n",
        "        predictions.append(result)\n",
        "        #print('> predicted=' + repr(result) + ', actual=' + repr(testSet[x][-1]))\n",
        "    # calcul metrics\n",
        "    accuracy = getAccuracy(testSet, predictions)\n",
        "    print('Accuracy: ', accuracy)\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SPK-2TTxC2F",
        "outputId": "a044f453-b167-49b9-ed6c-23b2ab99ba15"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: 100\n",
            "Test set: 49\n",
            "Accuracy:  97.95918367346938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Another distance metric\n",
        "\n",
        "In this part, you are asked to define another distance metric in addition to the Euclidean distance."
      ],
      "metadata": {
        "id": "3Jyqk7hB22YO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cFWfYcOG9RLY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}